{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chorus: End-to-End Federated LoRA Test\n",
    "\n",
    "**What this tests:** 3 clients each train a LoRA adapter on their private slice of data, submit to a Chorus server, which aggregates them using FedEx-LoRA. We verify the federated model outperforms any single client.\n",
    "\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| Model | `Qwen/Qwen2.5-0.5B-Instruct` (490M params) |\n",
    "| Dataset | `databricks/databricks-dolly-15k` (5K per client) |\n",
    "| LoRA rank | 16 |\n",
    "| Clients | 3 (sequential training, shared GPU) |\n",
    "| Aggregation | FedEx-LoRA (SVD-optimal) |\n",
    "| Runtime | ~30-45 min on T4 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install Chorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'chorus[peft] @ git+https://github.com/varmabudharaju/chorus.git'\n",
    "!pip install -q bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch, gc, os, time, math, subprocess, logging\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s [%(name)s] %(message)s', datefmt='%H:%M:%S')\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\nif device == \"cuda\":\n    gpu_props = torch.cuda.get_device_properties(0)\n    print(f\"GPU: {gpu_props.name}\")\n    print(f\"VRAM: {gpu_props.total_memory / 1e9:.1f} GB\")\n    print(f\"bf16 supported: {torch.cuda.is_bf16_supported()}\")\nelse:\n    print(\"WARNING: No GPU! Go to Runtime -> Change runtime type -> T4 GPU\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Dataset — Split Dolly-15K Across 3 Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "print(f\"Total examples: {len(ds)}\")\n",
    "print(f\"Categories: {sorted(ds.unique('category'))}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(f\"  instruction: {ds[0]['instruction'][:100]}\")\n",
    "print(f\"  context:     {ds[0]['context'][:100]}\")\n",
    "print(f\"  response:    {ds[0]['response'][:100]}\")\n",
    "\n",
    "# Shuffle and split into 3 client partitions\n",
    "ds = ds.shuffle(seed=42)\n",
    "client_datasets = [ds.shard(num_shards=3, index=i) for i in range(3)]\n",
    "\n",
    "# Save each client's data as JSON\n",
    "for i, cds in enumerate(client_datasets):\n",
    "    path = f\"/content/client_{i}.json\"\n",
    "    cds.to_json(path)\n",
    "    print(f\"Client {i}: {len(cds)} examples -> {path}\")\n",
    "\n",
    "# Hold out 20 examples for evaluation\n",
    "eval_ds = ds.select(range(20))\n",
    "print(f\"\\nHeld out {len(eval_ds)} examples for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Baseline — Measure Loss Before Any Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "USE_BF16 = torch.cuda.is_bf16_supported() if torch.cuda.is_available() else False\n",
    "DTYPE = torch.bfloat16 if USE_BF16 else torch.float16\n",
    "\n",
    "print(f\"Loading {MODEL_NAME} (dtype={DTYPE})...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "def measure_loss(model, examples, label):\n",
    "    \"\"\"Measure average cross-entropy loss on held-out examples.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for ex in examples:\n",
    "        text = f\"{ex['instruction']}\\n{ex.get('context', '')}\\n{ex['response']}\"\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            loss = model(**inputs, labels=inputs[\"input_ids\"]).loss\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(examples)\n",
    "    ppl = math.exp(avg_loss)\n",
    "    print(f\"  [{label}] Loss: {avg_loss:.4f} | Perplexity: {ppl:.2f}\")\n",
    "    return avg_loss, ppl\n",
    "\n",
    "\n",
    "# Baseline\n",
    "base_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=DTYPE).to(device)\n",
    "baseline_loss, baseline_ppl = measure_loss(base_model, eval_ds, \"Baseline (no training)\")\n",
    "del base_model; gc.collect(); torch.cuda.empty_cache()\n",
    "print(\"Baseline measured. Model unloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Start the Chorus Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import requests\nimport threading\nimport socket\n\n# Find a free port automatically\ndef find_free_port():\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind((\"127.0.0.1\", 0))\n        return s.getsockname()[1]\n\nSERVER_PORT = find_free_port()\nSERVER_URL = f\"http://127.0.0.1:{SERVER_PORT}\"\nprint(f\"Using port: {SERVER_PORT}\")\n\n# Start Chorus server in a background thread\nfrom chorus.server.app import configure, app\nimport uvicorn\n\nconfigure(\n    model_id=MODEL_NAME,\n    data_dir=\"/content/chorus_data\",\n    strategy=\"fedex-lora\",\n    min_deltas=3,\n)\n\nserver_error = []\n\ndef run_server():\n    try:\n        uvicorn.run(app, host=\"127.0.0.1\", port=SERVER_PORT, log_level=\"warning\")\n    except Exception as e:\n        server_error.append(str(e))\n\nserver_thread = threading.Thread(target=run_server, daemon=True)\nserver_thread.start()\n\nprint(\"Starting Chorus server...\")\nfor i in range(15):\n    time.sleep(1)\n    if server_error:\n        print(f\"ERROR: Server crashed: {server_error[0]}\")\n        break\n    try:\n        r = requests.get(f\"{SERVER_URL}/health\")\n        if r.status_code == 200:\n            health = r.json()\n            print(f\"Server is running at {SERVER_URL}\")\n            print(f\"  Model:    {health['model_id']}\")\n            print(f\"  Strategy: {health['strategy']}\")\n            break\n    except requests.ConnectionError:\n        print(f\"  Waiting... ({i+1}s)\")\nelse:\n    if not server_error:\n        print(\"ERROR: Server failed to start after 15 seconds\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train 3 Clients and Submit Deltas\n",
    "\n",
    "Each client:\n",
    "1. Loads Qwen2.5-0.5B\n",
    "2. Trains LoRA (rank 16) on its ~5K examples\n",
    "3. Submits the delta to the Chorus server\n",
    "4. Unloads the model to free VRAM for the next client\n",
    "\n",
    "The 3rd submission triggers FedEx-LoRA aggregation automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from chorus.client.trainer import LoRATrainer\nfrom chorus.client.sdk import ChorusClient\n\n# SERVER_URL is set in Step 3 (dynamic port)\nNUM_CLIENTS = 3\nclient_losses = []\n\nfor i in range(NUM_CLIENTS):\n    print(f\"\\n{'='*60}\")\n    print(f\"CLIENT {i}: Training on {len(client_datasets[i])} examples\")\n    print(f\"{'='*60}\")\n\n    output_dir = f\"/content/adapter_client_{i}\"\n\n    # Train\n    trainer = LoRATrainer(\n        base_model=MODEL_NAME,\n        dataset=f\"/content/client_{i}.json\",\n        output_dir=output_dir,\n        lora_rank=16,\n        lora_alpha=32,\n        learning_rate=2e-4,\n        num_epochs=1,\n        per_device_batch_size=4,\n        gradient_accumulation_steps=4,\n        max_seq_length=512,\n        bf16=USE_BF16,\n        fp16=not USE_BF16 and torch.cuda.is_available(),\n        dataloader_pin_memory=False,\n    )\n\n    adapter_path = trainer.train()\n    print(f\"  Adapter saved to: {adapter_path}\")\n\n    # Measure this single client's loss\n    from peft import PeftModel\n    single_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=DTYPE).to(device)\n    single_model = PeftModel.from_pretrained(single_model, output_dir)\n    loss_i, ppl_i = measure_loss(single_model, eval_ds, f\"Client {i} alone\")\n    client_losses.append((loss_i, ppl_i))\n    del single_model; gc.collect(); torch.cuda.empty_cache()\n\n    # Submit to Chorus server\n    client = ChorusClient(\n        server=SERVER_URL,\n        model_id=MODEL_NAME,\n        client_id=f\"client-{i}\",\n    )\n    result = client.submit_delta(\n        adapter_path=output_dir,\n        dataset_size=len(client_datasets[i]),\n    )\n    client.close()\n\n    print(f\"  Submitted! Deltas: {result['deltas_received']}/{result['min_deltas']}\")\n    if result['aggregated']:\n        print(f\"  >>> FedEx-LoRA AGGREGATION TRIGGERED! <<<\")\n\nprint(f\"\\nAll {NUM_CLIENTS} clients done.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Pull Aggregated Adapter and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Pull the aggregated adapter from the server\n",
    "client = ChorusClient(server=SERVER_URL, model_id=MODEL_NAME)\n",
    "agg_path = client.pull_latest(output_path=\"/content/adapter_federated\")\n",
    "client.close()\n",
    "\n",
    "print(f\"Aggregated adapter: {agg_path}\")\n",
    "print(f\"File size: {os.path.getsize(agg_path) / 1e6:.2f} MB\")\n",
    "\n",
    "# Inspect tensors\n",
    "agg_tensors = load_file(str(agg_path))\n",
    "print(f\"Tensors: {len(agg_tensors)}\")\n",
    "for k, v in sorted(agg_tensors.items())[:4]:\n",
    "    print(f\"  {k}: {v.shape}\")\n",
    "print(f\"  ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model + inject aggregated adapter\n",
    "fed_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=DTYPE).to(device)\n",
    "\n",
    "# Apply a LoRA config matching the aggregated adapter's rank\n",
    "ranks = set(v.shape[0] for k, v in agg_tensors.items() if \"lora_A\" in k)\n",
    "agg_rank = max(ranks)\n",
    "print(f\"Aggregated adapter rank: {agg_rank}\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=agg_rank, lora_alpha=agg_rank,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.0, bias=\"none\", task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "fed_model = get_peft_model(fed_model, lora_config)\n",
    "\n",
    "# Load aggregated weights into the PEFT model\n",
    "state_dict = fed_model.state_dict()\n",
    "loaded = 0\n",
    "for k, v in agg_tensors.items():\n",
    "    peft_key = (\n",
    "        \"base_model.model.\" +\n",
    "        k.replace(\".lora_A.weight\", \".lora_A.default.weight\")\n",
    "         .replace(\".lora_B.weight\", \".lora_B.default.weight\")\n",
    "    )\n",
    "    if peft_key in state_dict:\n",
    "        state_dict[peft_key] = v.to(state_dict[peft_key].dtype).to(device)\n",
    "        loaded += 1\n",
    "fed_model.load_state_dict(state_dict)\n",
    "print(f\"Loaded {loaded}/{len(agg_tensors)} tensors into model\")\n",
    "\n",
    "# Evaluate\n",
    "fed_loss, fed_ppl = measure_loss(fed_model, eval_ds, \"Federated (FedEx-LoRA)\")\n",
    "del fed_model; gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"\\n{'Model':<35} {'Loss':>8} {'Perplexity':>12}\")\n",
    "print(\"-\" * 58)\n",
    "\n",
    "print(f\"{'Baseline (no training)':<35} {baseline_loss:>8.4f} {baseline_ppl:>12.2f}\")\n",
    "for i, (l, p) in enumerate(client_losses):\n",
    "    print(f\"{'Client ' + str(i) + ' alone':<35} {l:>8.4f} {p:>12.2f}\")\n",
    "print(f\"{'Federated (FedEx-LoRA, 3 clients)':<35} {fed_loss:>8.4f} {fed_ppl:>12.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 58)\n",
    "avg_client_loss = sum(l for l, _ in client_losses) / len(client_losses)\n",
    "print(f\"\\nBaseline -> Federated:  {(baseline_loss - fed_loss) / baseline_loss * 100:+.1f}% loss reduction\")\n",
    "print(f\"Avg client -> Federated: {(avg_client_loss - fed_loss) / avg_client_loss * 100:+.1f}% loss reduction\")\n",
    "\n",
    "if fed_loss < avg_client_loss:\n",
    "    print(\"\\n>>> Federation improved over individual clients! Chorus works. <<<\")\n",
    "else:\n",
    "    print(\"\\n>>> Federation did not beat avg client. May need more rounds or tuning. <<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Generation Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick generation comparison: base vs federated\n",
    "test_prompts = [\n",
    "    \"Explain the difference between machine learning and deep learning.\",\n",
    "    \"What are the main causes of climate change?\",\n",
    "    \"Summarize the plot of Romeo and Juliet in 3 sentences.\",\n",
    "]\n",
    "\n",
    "\n",
    "def generate(model, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs, max_new_tokens=150, do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(out[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "# Load both models for comparison\n",
    "print(\"Loading base model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=DTYPE).to(device)\n",
    "\n",
    "print(\"Loading federated model...\")\n",
    "fed_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=DTYPE).to(device)\n",
    "fed_model = get_peft_model(fed_model, lora_config)\n",
    "state_dict = fed_model.state_dict()\n",
    "for k, v in agg_tensors.items():\n",
    "    peft_key = (\n",
    "        \"base_model.model.\" +\n",
    "        k.replace(\".lora_A.weight\", \".lora_A.default.weight\")\n",
    "         .replace(\".lora_B.weight\", \".lora_B.default.weight\")\n",
    "    )\n",
    "    if peft_key in state_dict:\n",
    "        state_dict[peft_key] = v.to(state_dict[peft_key].dtype).to(device)\n",
    "fed_model.load_state_dict(state_dict)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nQ: {prompt}\")\n",
    "    print(f\"\\n  [Base]:      {generate(base_model, prompt)[:300]}\")\n",
    "    print(f\"\\n  [Federated]: {generate(fed_model, prompt)[:300]}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "del base_model, fed_model; gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Server runs as a daemon thread — it stops when the notebook stops.\nprint(\"Done! The Chorus server will shut down when this Colab session ends.\")\nprint(\"All results are above.\")"
  }
 ]
}